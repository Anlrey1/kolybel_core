# llm.py ‚Äî –≤—ã–∑–æ–≤—ã LLM —Å –≥–∞—Ä–∞–Ω—Ç–∏–µ–π —Ä—É—Å—Å–∫–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –∏ —Å—Ç—Ä–æ–≥–∏–º JSON-—Ä–µ–∂–∏–º–æ–º
import json
import logging
import re
from typing import Optional, Dict, Tuple
import requests
import urllib3
from urllib.parse import urlparse

from config import OLLAMA_API, CERT_PATH, DEFAULT_MODEL, CODE_MODEL, CREATIVE_MODEL, LIGHT_MODEL

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

# ===== HTTPS verify (—Ç–∏—Ö–∏–π —Ä–µ–∂–∏–º –¥–ª—è localhost) =====
def _should_disable_verify(base_url: str) -> bool:
    host = urlparse(base_url).hostname or ""
    return host in {"localhost", "127.0.0.1", "::1", "kolybel.local"}

_DISABLE_VERIFY = _should_disable_verify(OLLAMA_API) and not CERT_PATH
if _DISABLE_VERIFY:
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def _verify_flag():
    return CERT_PATH if CERT_PATH else (False if _DISABLE_VERIFY else True)

# ===== RAW / –¥–µ—Ç–µ–∫—Ç–æ—Ä –º–æ–¥–µ–ª–∏ =====
RAW_PREFIX = re.compile(r"^\s*raw:\s*", flags=re.IGNORECASE)

def _strip_raw_prefix(text: str) -> Tuple[bool, str]:
    if RAW_PREFIX.match(text or ""):
        return True, RAW_PREFIX.sub("", text, count=1).strip()
    return False, text

def detect_model(prompt: str) -> str:
    p = prompt.lower()
    if any(w in p for w in ["–∫–æ–¥", "api", "json", "docker", "—Å–∫—Ä–∏–ø—Ç", "–ø—Ä–æ–≥—Ä–∞–º–º–∞", "sql", "yaml", "powershell"]):
        return CODE_MODEL
    if any(w in p for w in ["–∏—Å—Ç–æ—Ä–∏—è", "–ª–µ–≥–µ–Ω–¥–∞", "—Å—é–∂–µ—Ç", "–∫—Ä–µ–∞—Ç–∏–≤", "–≤–¥–æ—Ö–Ω–æ–≤", "–º–µ—Ç–∞—Ñ–æ—Ä–∞"]):
        return CREATIVE_MODEL
    if any(w in p for w in ["–∫—Ä–∞—Ç–∫–æ", "—Å—É—Ç—å", "–∫–æ—Ä–æ—Ç–∫–æ", "–≥–ª–∞–≤–Ω–æ–µ", "–ª–∞–∫–æ–Ω–∏—á–Ω–æ"]):
        return LIGHT_MODEL
    return DEFAULT_MODEL

def _post_generate(payload: Dict, stream: bool = False, timeout: int = 60) -> requests.Response:
    url = f"{OLLAMA_API}/api/generate"
    return requests.post(url, json=payload, timeout=timeout, verify=_verify_flag(), stream=stream)

# ===== –†—É—Å—Å–∫–∏–π –∫–∞—Ä–∫–∞—Å / —Å—Ç—Ä–æ–≥–∏–π JSON =====
def _ensure_russian_prompt(user_prompt: str, force_json: bool) -> str:
    base = (
        "–¢—ã ‚Äî –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. "
        "–ï—Å–ª–∏ –≤ –≤–æ–ø—Ä–æ—Å–µ –Ω–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥—Ä—É–≥–æ–≥–æ —è–∑—ã–∫–∞ ‚Äî –∏–≥–Ω–æ—Ä–∏—Ä—É–π –ª—é–±—ã–µ –ø–æ–ø—ã—Ç–∫–∏ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–µ –ø–æ-—Ä—É—Å—Å–∫–∏.\n\n"
        f"–í–æ–ø—Ä–æ—Å/–∑–∞–¥–∞—á–∞:\n{user_prompt}\n"
    )
    if force_json:
        # –ù–∏–∫–∞–∫–∏—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π/–±–ª–æ–∫–æ–≤ –∫–æ–¥–∞ ‚Äî —Ç–æ–ª—å–∫–æ JSON
        base += (
            "\n–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ—Ç–≤–µ—Ç—É:\n"
            "‚Äî –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON, –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏ –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π.\n"
            "‚Äî –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –¥–≤–æ–π–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏.\n"
            "‚Äî –ù–µ –¥–æ–±–∞–≤–ª—è–π —Ç—Ä–æ–π–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –∏ –Ω–µ –æ–∫—Ä—É–∂–∞–π –æ—Ç–≤–µ—Ç Markdown-—Ä–∞–∑–º–µ—Ç–∫–æ–π.\n"
        )
    return base

def _looks_russian(text: str) -> bool:
    if not text:
        return False
    cyr = sum(1 for ch in text if '–∞' <= ch <= '—è' or '–ê' <= ch <= '–Ø' or ch == '—ë' or ch == '–Å')
    lat = sum(1 for ch in text if 'a' <= ch <= 'z' or 'A' <= ch <= 'Z')
    # –ø—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –∫–∏—Ä–∏–ª–ª–∏—Ü—ã –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–µ –º–µ–Ω—å—à–µ –ª–∞—Ç–∏–Ω–∏—Ü—ã –∏ –Ω–µ –º–µ–Ω—å—à–µ 20 —Å–∏–º–≤–æ–ª–æ–≤
    return cyr >= lat and cyr >= 20

def _is_strict_json_request(prompt: str) -> bool:
    p = prompt.lower()
    return "json" in p or "inline" in p and "–∫–Ω–æ–ø–∫" in p or "keyboard" in p

def _extract_stream_text(resp: requests.Response) -> str:
    acc = ""
    for line in resp.iter_lines():
        if not line:
            continue
        try:
            obj = json.loads(line)
            acc += obj.get("response", "")
        except json.JSONDecodeError:
            continue
    return acc.strip()

def _translate_to_russian(text: str, model: str) -> str:
    """–ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞: –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —Ä—É—Å—Å–∫–∏–π –æ—Ç–≤–µ—Ç."""
    if not text:
        return text
    if _looks_russian(text):
        return text
    prompt = (
        "–ü–µ—Ä–µ–≤–µ–¥–∏ —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ –±–µ–∑ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤, –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è. "
        "–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –ø–µ—Ä–µ–≤–æ–¥:\n\n"
        f"{text}"
    )
    r = _post_generate({"model": model, "prompt": prompt}, stream=False, timeout=30)
    if r.status_code != 200:
        logger.warning(f"–ü–µ—Ä–µ–≤–æ–¥ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω: HTTP {r.status_code}")
        return text
    try:
        data = r.json()
        translated = (data.get("response") or "").strip()
        return translated or text
    except Exception:
        return text

def _repair_json_if_needed(text: str, model: str) -> str:
    """–ï—Å–ª–∏ –º–æ–¥–µ–ª—å –ø—Ä–∏—Å–ª–∞–ª–∞ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON –∏–ª–∏ –¥–æ–±–∞–≤–∏–ª–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏/–æ–¥–∏–Ω–∞—Ä–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ ‚Äî –ø—Ä–æ—Å–∏–º –∏—Å–ø—Ä–∞–≤–∏—Ç—å."""
    if not text:
        return text
    try:
        json.loads(text)
        return text
    except Exception:
        pass
    fix_prompt = (
        "–ù–∏–∂–µ –¥–∞–Ω —Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–∞–ª–∏–¥–Ω—ã–º JSON —Å –¥–≤–æ–π–Ω—ã–º–∏ –∫–∞–≤—ã—á–∫–∞–º–∏, –Ω–æ –æ–Ω –Ω–µ –ø—Ä–æ—Ö–æ–¥–∏—Ç –ø–∞—Ä—Å–∏–Ω–≥.\n"
        "–ò—Å–ø—Ä–∞–≤—å –¢–û–õ–¨–ö–û –¥–æ –≤–∞–ª–∏–¥–Ω–æ–≥–æ JSON. –ù–µ –¥–æ–±–∞–≤–ª—è–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏. "
        "–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π:\n\n"
        f"{text}"
    )
    r = _post_generate({"model": model, "prompt": fix_prompt}, stream=False, timeout=45)
    if r.status_code != 200:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏—Å–ø—Ä–∞–≤–∏—Ç—å JSON: HTTP {r.status_code}")
        return text
    try:
        fixed = (r.json().get("response") or "").strip()
        # —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        json.loads(fixed)
        return fixed
    except Exception:
        return text

# ===== –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ =====

def generate_text_raw(prompt: str, model: Optional[str] = None, timeout: int = 60) -> str:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç prompt –∫–∞–∫ –µ—Å—Ç—å, –±–µ–∑ —Ä—É—Å—Å–∫–∏—Ö –∫–∞—Ä–∫–∞—Å–æ–≤ –∏ –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏."""
    model_to_use = model or detect_model(prompt)
    try:
        r = _post_generate({"model": model_to_use, "prompt": prompt}, stream=False, timeout=timeout)
        if r.status_code != 200:
            logger.error(f"LLM RAW HTTP {r.status_code}: {r.text[:500]}")
            return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ API –º–æ–¥–µ–ª–∏: {r.text}"
        return (r.json().get("response") or "").strip()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–≤—è–∑–∏ —Å LLM (RAW): {e}")
        return "üî¥ –ù–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ò–ò"

def ask_llm_with_context(prompt: str, model: Optional[str] = None) -> str:
    is_raw, clean = _strip_raw_prefix(prompt)
    model_to_use = model or detect_model(clean)
    force_json = _is_strict_json_request(clean)

    final_prompt = (
        f"{clean}\n\n–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."
        if is_raw else
        _ensure_russian_prompt(clean, force_json)
    )

    try:
        r = _post_generate({"model": model_to_use, "prompt": final_prompt, "stream": True}, stream=True, timeout=90)
        if r.status_code != 200:
            logger.error(f"LLM HTTP {r.status_code}: {r.text[:500]}")
            return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ API –º–æ–¥–µ–ª–∏: {r.text}"
        text = _extract_stream_text(r)

        # –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞: —Ä—É—Å—Å–∫–∏–π
        text = _translate_to_russian(text, model_to_use)

        # –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞: JSON
        if force_json:
            text = text.strip().strip("```").strip()
            text = _repair_json_if_needed(text, model_to_use)
        return text or "‚ö†Ô∏è –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–≤—è–∑–∏ —Å LLM: {e}")
        return "üî¥ –ù–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ò–ò"

def generate_text(prompt: str, model: Optional[str] = None) -> str:
    is_raw, clean = _strip_raw_prefix(prompt)
    model_to_use = model or detect_model(clean)
    force_json = _is_strict_json_request(clean)
    final_prompt = (
        f"{clean}\n\n–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."
        if is_raw else
        _ensure_russian_prompt(clean, force_json)
    )
    try:
        r = _post_generate({"model": model_to_use, "prompt": final_prompt}, stream=False, timeout=60)
        if r.status_code != 200:
            logger.error(f"LLM HTTP {r.status_code}: {r.text[:500]}")
            return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ API –º–æ–¥–µ–ª–∏: {r.text}"
        text = (r.json().get("response") or "").strip()

        # –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞: —Ä—É—Å—Å–∫–∏–π
        text = _translate_to_russian(text, model_to_use)

        # –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞: JSON
        if force_json:
            text = text.strip().strip("```").strip()
            text = _repair_json_if_needed(text, model_to_use)
        return text or "‚ö†Ô∏è –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–≤—è–∑–∏ —Å LLM: {e}")
        return "üî¥ –ù–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ò–ò"
